{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/shane/Development/DHDRNet/fastdata\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dhdrnet.util import DATA_DIR, ROOT_DIR\n",
    "\n",
    "MODEL_DIR = ROOT_DIR / \"checkpoints\"\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"10\" halign=\"left\">mse</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">ssim</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ev</th>\n",
       "      <th>-3.00</th>\n",
       "      <th>-2.75</th>\n",
       "      <th>-2.50</th>\n",
       "      <th>-2.25</th>\n",
       "      <th>-2.00</th>\n",
       "      <th>-1.75</th>\n",
       "      <th>-1.50</th>\n",
       "      <th>-1.25</th>\n",
       "      <th>-1.00</th>\n",
       "      <th>-0.75</th>\n",
       "      <th>...</th>\n",
       "      <th>3.75</th>\n",
       "      <th>4.00</th>\n",
       "      <th>4.25</th>\n",
       "      <th>4.50</th>\n",
       "      <th>4.75</th>\n",
       "      <th>5.00</th>\n",
       "      <th>5.25</th>\n",
       "      <th>5.50</th>\n",
       "      <th>5.75</th>\n",
       "      <th>6.00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0006_20160721_170707_736</th>\n",
       "      <td>1564.444742</td>\n",
       "      <td>1620.747432</td>\n",
       "      <td>1666.827206</td>\n",
       "      <td>1694.827552</td>\n",
       "      <td>1703.434451</td>\n",
       "      <td>1598.156467</td>\n",
       "      <td>1594.859254</td>\n",
       "      <td>1543.512098</td>\n",
       "      <td>1416.238552</td>\n",
       "      <td>1255.256251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959734</td>\n",
       "      <td>0.953911</td>\n",
       "      <td>0.947888</td>\n",
       "      <td>0.942444</td>\n",
       "      <td>0.938234</td>\n",
       "      <td>0.935391</td>\n",
       "      <td>0.933572</td>\n",
       "      <td>0.932935</td>\n",
       "      <td>0.932762</td>\n",
       "      <td>0.931905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_20160721_175239_909</th>\n",
       "      <td>4833.678364</td>\n",
       "      <td>4931.049788</td>\n",
       "      <td>5023.474798</td>\n",
       "      <td>5096.684604</td>\n",
       "      <td>5149.722950</td>\n",
       "      <td>5132.641241</td>\n",
       "      <td>5127.621899</td>\n",
       "      <td>5039.689928</td>\n",
       "      <td>4886.487238</td>\n",
       "      <td>4668.281993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957424</td>\n",
       "      <td>0.949567</td>\n",
       "      <td>0.937777</td>\n",
       "      <td>0.920994</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>0.878370</td>\n",
       "      <td>0.858490</td>\n",
       "      <td>0.840515</td>\n",
       "      <td>0.821926</td>\n",
       "      <td>0.801410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_20160721_181525_062</th>\n",
       "      <td>4030.755679</td>\n",
       "      <td>4099.319882</td>\n",
       "      <td>4154.594938</td>\n",
       "      <td>4191.564140</td>\n",
       "      <td>4196.336224</td>\n",
       "      <td>4112.124243</td>\n",
       "      <td>4107.827877</td>\n",
       "      <td>4003.839777</td>\n",
       "      <td>3848.204339</td>\n",
       "      <td>3646.137740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969495</td>\n",
       "      <td>0.965626</td>\n",
       "      <td>0.960337</td>\n",
       "      <td>0.953310</td>\n",
       "      <td>0.942647</td>\n",
       "      <td>0.928551</td>\n",
       "      <td>0.910231</td>\n",
       "      <td>0.887124</td>\n",
       "      <td>0.857294</td>\n",
       "      <td>0.822510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_20160722_100126_028</th>\n",
       "      <td>3096.586446</td>\n",
       "      <td>3195.740610</td>\n",
       "      <td>3285.280822</td>\n",
       "      <td>3355.353795</td>\n",
       "      <td>3393.217263</td>\n",
       "      <td>3398.260426</td>\n",
       "      <td>3304.577579</td>\n",
       "      <td>3260.788758</td>\n",
       "      <td>3106.662492</td>\n",
       "      <td>2886.394583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963612</td>\n",
       "      <td>0.955471</td>\n",
       "      <td>0.945895</td>\n",
       "      <td>0.935127</td>\n",
       "      <td>0.923266</td>\n",
       "      <td>0.910170</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>0.876095</td>\n",
       "      <td>0.870559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_20160722_100951_201</th>\n",
       "      <td>256.802163</td>\n",
       "      <td>291.744275</td>\n",
       "      <td>325.948450</td>\n",
       "      <td>357.335873</td>\n",
       "      <td>380.441056</td>\n",
       "      <td>381.866729</td>\n",
       "      <td>382.741421</td>\n",
       "      <td>353.604755</td>\n",
       "      <td>303.291687</td>\n",
       "      <td>235.769308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975440</td>\n",
       "      <td>0.975728</td>\n",
       "      <td>0.975196</td>\n",
       "      <td>0.974106</td>\n",
       "      <td>0.972672</td>\n",
       "      <td>0.971321</td>\n",
       "      <td>0.970290</td>\n",
       "      <td>0.969488</td>\n",
       "      <td>0.968797</td>\n",
       "      <td>0.968433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_173210_443</th>\n",
       "      <td>396.788974</td>\n",
       "      <td>414.150080</td>\n",
       "      <td>424.499389</td>\n",
       "      <td>421.893856</td>\n",
       "      <td>407.417568</td>\n",
       "      <td>341.777813</td>\n",
       "      <td>338.061688</td>\n",
       "      <td>290.665286</td>\n",
       "      <td>244.182324</td>\n",
       "      <td>212.416530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957310</td>\n",
       "      <td>0.956473</td>\n",
       "      <td>0.956189</td>\n",
       "      <td>0.956502</td>\n",
       "      <td>0.957197</td>\n",
       "      <td>0.958147</td>\n",
       "      <td>0.958975</td>\n",
       "      <td>0.959477</td>\n",
       "      <td>0.959802</td>\n",
       "      <td>0.960030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_194029_165</th>\n",
       "      <td>4089.551454</td>\n",
       "      <td>4099.503758</td>\n",
       "      <td>4076.524716</td>\n",
       "      <td>4038.705294</td>\n",
       "      <td>3962.634683</td>\n",
       "      <td>3856.468872</td>\n",
       "      <td>3444.100464</td>\n",
       "      <td>3442.939489</td>\n",
       "      <td>3363.027961</td>\n",
       "      <td>3164.719363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971709</td>\n",
       "      <td>0.973337</td>\n",
       "      <td>0.968661</td>\n",
       "      <td>0.959896</td>\n",
       "      <td>0.948609</td>\n",
       "      <td>0.937562</td>\n",
       "      <td>0.926985</td>\n",
       "      <td>0.919514</td>\n",
       "      <td>0.911793</td>\n",
       "      <td>0.899032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_195108_436</th>\n",
       "      <td>3136.258062</td>\n",
       "      <td>3158.604146</td>\n",
       "      <td>3150.862320</td>\n",
       "      <td>3122.928498</td>\n",
       "      <td>3074.531499</td>\n",
       "      <td>2977.176778</td>\n",
       "      <td>2857.079921</td>\n",
       "      <td>2593.799426</td>\n",
       "      <td>2534.649179</td>\n",
       "      <td>2345.410856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962358</td>\n",
       "      <td>0.950379</td>\n",
       "      <td>0.938581</td>\n",
       "      <td>0.930643</td>\n",
       "      <td>0.926860</td>\n",
       "      <td>0.926224</td>\n",
       "      <td>0.920695</td>\n",
       "      <td>0.908220</td>\n",
       "      <td>0.886170</td>\n",
       "      <td>0.857713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_214630_530</th>\n",
       "      <td>5143.751095</td>\n",
       "      <td>5265.341578</td>\n",
       "      <td>5354.983200</td>\n",
       "      <td>5412.049453</td>\n",
       "      <td>5419.047871</td>\n",
       "      <td>5384.352295</td>\n",
       "      <td>5297.645468</td>\n",
       "      <td>5154.911430</td>\n",
       "      <td>4959.021309</td>\n",
       "      <td>4355.826203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954547</td>\n",
       "      <td>0.946708</td>\n",
       "      <td>0.936760</td>\n",
       "      <td>0.924288</td>\n",
       "      <td>0.909627</td>\n",
       "      <td>0.892904</td>\n",
       "      <td>0.874691</td>\n",
       "      <td>0.856480</td>\n",
       "      <td>0.839548</td>\n",
       "      <td>0.825584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_221141_886</th>\n",
       "      <td>7165.308185</td>\n",
       "      <td>7285.930914</td>\n",
       "      <td>7377.103449</td>\n",
       "      <td>7451.839310</td>\n",
       "      <td>7482.942462</td>\n",
       "      <td>7485.706860</td>\n",
       "      <td>7433.829155</td>\n",
       "      <td>7331.016986</td>\n",
       "      <td>7160.985082</td>\n",
       "      <td>6919.238193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939660</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.929212</td>\n",
       "      <td>0.924560</td>\n",
       "      <td>0.919437</td>\n",
       "      <td>0.914986</td>\n",
       "      <td>0.909897</td>\n",
       "      <td>0.903522</td>\n",
       "      <td>0.894415</td>\n",
       "      <td>0.881807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                            mse                                         \\\n",
       "ev                              -3.00        -2.75        -2.50        -2.25   \n",
       "0006_20160721_170707_736  1564.444742  1620.747432  1666.827206  1694.827552   \n",
       "0006_20160721_175239_909  4833.678364  4931.049788  5023.474798  5096.684604   \n",
       "0006_20160721_181525_062  4030.755679  4099.319882  4154.594938  4191.564140   \n",
       "0006_20160722_100126_028  3096.586446  3195.740610  3285.280822  3355.353795   \n",
       "0006_20160722_100951_201   256.802163   291.744275   325.948450   357.335873   \n",
       "...                               ...          ...          ...          ...   \n",
       "c483_20150901_173210_443   396.788974   414.150080   424.499389   421.893856   \n",
       "c483_20150901_194029_165  4089.551454  4099.503758  4076.524716  4038.705294   \n",
       "c483_20150901_195108_436  3136.258062  3158.604146  3150.862320  3122.928498   \n",
       "c483_20150901_214630_530  5143.751095  5265.341578  5354.983200  5412.049453   \n",
       "c483_20150901_221141_886  7165.308185  7285.930914  7377.103449  7451.839310   \n",
       "\n",
       "metric                                                                        \\\n",
       "ev                              -2.00        -1.75        -1.50        -1.25   \n",
       "0006_20160721_170707_736  1703.434451  1598.156467  1594.859254  1543.512098   \n",
       "0006_20160721_175239_909  5149.722950  5132.641241  5127.621899  5039.689928   \n",
       "0006_20160721_181525_062  4196.336224  4112.124243  4107.827877  4003.839777   \n",
       "0006_20160722_100126_028  3393.217263  3398.260426  3304.577579  3260.788758   \n",
       "0006_20160722_100951_201   380.441056   381.866729   382.741421   353.604755   \n",
       "...                               ...          ...          ...          ...   \n",
       "c483_20150901_173210_443   407.417568   341.777813   338.061688   290.665286   \n",
       "c483_20150901_194029_165  3962.634683  3856.468872  3444.100464  3442.939489   \n",
       "c483_20150901_195108_436  3074.531499  2977.176778  2857.079921  2593.799426   \n",
       "c483_20150901_214630_530  5419.047871  5384.352295  5297.645468  5154.911430   \n",
       "c483_20150901_221141_886  7482.942462  7485.706860  7433.829155  7331.016986   \n",
       "\n",
       "metric                                              ...      ssim            \\\n",
       "ev                              -1.00        -0.75  ...      3.75      4.00   \n",
       "0006_20160721_170707_736  1416.238552  1255.256251  ...  0.959734  0.953911   \n",
       "0006_20160721_175239_909  4886.487238  4668.281993  ...  0.957424  0.949567   \n",
       "0006_20160721_181525_062  3848.204339  3646.137740  ...  0.969495  0.965626   \n",
       "0006_20160722_100126_028  3106.662492  2886.394583  ...  0.963612  0.955471   \n",
       "0006_20160722_100951_201   303.291687   235.769308  ...  0.975440  0.975728   \n",
       "...                               ...          ...  ...       ...       ...   \n",
       "c483_20150901_173210_443   244.182324   212.416530  ...  0.957310  0.956473   \n",
       "c483_20150901_194029_165  3363.027961  3164.719363  ...  0.971709  0.973337   \n",
       "c483_20150901_195108_436  2534.649179  2345.410856  ...  0.962358  0.950379   \n",
       "c483_20150901_214630_530  4959.021309  4355.826203  ...  0.954547  0.946708   \n",
       "c483_20150901_221141_886  7160.985082  6919.238193  ...  0.939660  0.934590   \n",
       "\n",
       "metric                                                                      \\\n",
       "ev                            4.25      4.50      4.75      5.00      5.25   \n",
       "0006_20160721_170707_736  0.947888  0.942444  0.938234  0.935391  0.933572   \n",
       "0006_20160721_175239_909  0.937777  0.920994  0.899950  0.878370  0.858490   \n",
       "0006_20160721_181525_062  0.960337  0.953310  0.942647  0.928551  0.910231   \n",
       "0006_20160722_100126_028  0.945895  0.935127  0.923266  0.910170  0.896825   \n",
       "0006_20160722_100951_201  0.975196  0.974106  0.972672  0.971321  0.970290   \n",
       "...                            ...       ...       ...       ...       ...   \n",
       "c483_20150901_173210_443  0.956189  0.956502  0.957197  0.958147  0.958975   \n",
       "c483_20150901_194029_165  0.968661  0.959896  0.948609  0.937562  0.926985   \n",
       "c483_20150901_195108_436  0.938581  0.930643  0.926860  0.926224  0.920695   \n",
       "c483_20150901_214630_530  0.936760  0.924288  0.909627  0.892904  0.874691   \n",
       "c483_20150901_221141_886  0.929212  0.924560  0.919437  0.914986  0.909897   \n",
       "\n",
       "metric                                                  \n",
       "ev                            5.50      5.75      6.00  \n",
       "0006_20160721_170707_736  0.932935  0.932762  0.931905  \n",
       "0006_20160721_175239_909  0.840515  0.821926  0.801410  \n",
       "0006_20160721_181525_062  0.887124  0.857294  0.822510  \n",
       "0006_20160722_100126_028  0.884880  0.876095  0.870559  \n",
       "0006_20160722_100951_201  0.969488  0.968797  0.968433  \n",
       "...                            ...       ...       ...  \n",
       "c483_20150901_173210_443  0.959477  0.959802  0.960030  \n",
       "c483_20150901_194029_165  0.919514  0.911793  0.899032  \n",
       "c483_20150901_195108_436  0.908220  0.886170  0.857713  \n",
       "c483_20150901_214630_530  0.856480  0.839548  0.825584  \n",
       "c483_20150901_221141_886  0.903522  0.894415  0.881807  \n",
       "\n",
       "[724 rows x 108 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "from dhdrnet.Dataset import RCDataset\n",
    "\n",
    "test_data = RCDataset(\n",
    "    df=pd.read_csv(ROOT_DIR / \"precomputed_data\" / \"store_current.csv\"),\n",
    "    exposure_path=DATA_DIR / \"correct_exposures\" / \"exposures\",\n",
    "    raw_dir=DATA_DIR / \"dngs\",\n",
    "    name_list=ROOT_DIR / \"precomputed_data\" / \"test_current.csv\",\n",
    "    transform=Compose([Resize((300, 300)), ToTensor()]),\n",
    "    metric=\"mse\",\n",
    ")\n",
    "test_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ev</th>\n",
       "      <th>-3.00</th>\n",
       "      <th>-2.75</th>\n",
       "      <th>-2.50</th>\n",
       "      <th>-2.25</th>\n",
       "      <th>-2.00</th>\n",
       "      <th>-1.75</th>\n",
       "      <th>-1.50</th>\n",
       "      <th>-1.25</th>\n",
       "      <th>-1.00</th>\n",
       "      <th>-0.75</th>\n",
       "      <th>...</th>\n",
       "      <th>3.75</th>\n",
       "      <th>4.00</th>\n",
       "      <th>4.25</th>\n",
       "      <th>4.50</th>\n",
       "      <th>4.75</th>\n",
       "      <th>5.00</th>\n",
       "      <th>5.25</th>\n",
       "      <th>5.50</th>\n",
       "      <th>5.75</th>\n",
       "      <th>6.00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">prob</th>\n",
       "      <th>0006_20160721_170707_736</th>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>0.012777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042720</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.038788</td>\n",
       "      <td>0.036664</td>\n",
       "      <td>0.034901</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.032077</td>\n",
       "      <td>0.031602</td>\n",
       "      <td>0.031327</td>\n",
       "      <td>0.030614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_20160721_175239_909</th>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049166</td>\n",
       "      <td>0.049012</td>\n",
       "      <td>0.048269</td>\n",
       "      <td>0.046416</td>\n",
       "      <td>0.043465</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>0.036753</td>\n",
       "      <td>0.033649</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>0.027636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_20160721_181525_062</th>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047626</td>\n",
       "      <td>0.047743</td>\n",
       "      <td>0.047628</td>\n",
       "      <td>0.047221</td>\n",
       "      <td>0.046454</td>\n",
       "      <td>0.045098</td>\n",
       "      <td>0.042875</td>\n",
       "      <td>0.039709</td>\n",
       "      <td>0.035463</td>\n",
       "      <td>0.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_20160722_100126_028</th>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046876</td>\n",
       "      <td>0.045750</td>\n",
       "      <td>0.043899</td>\n",
       "      <td>0.041213</td>\n",
       "      <td>0.037872</td>\n",
       "      <td>0.034099</td>\n",
       "      <td>0.030310</td>\n",
       "      <td>0.026915</td>\n",
       "      <td>0.024486</td>\n",
       "      <td>0.023014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_20160722_100951_201</th>\n",
       "      <td>0.029990</td>\n",
       "      <td>0.028178</td>\n",
       "      <td>0.026405</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.023579</td>\n",
       "      <td>0.023505</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.024971</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036685</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>0.036704</td>\n",
       "      <td>0.036516</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.036021</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>0.036956</td>\n",
       "      <td>0.037334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">mse</th>\n",
       "      <th>c483_20150901_173210_443</th>\n",
       "      <td>396.788974</td>\n",
       "      <td>414.150080</td>\n",
       "      <td>424.499389</td>\n",
       "      <td>421.893856</td>\n",
       "      <td>407.417568</td>\n",
       "      <td>341.777813</td>\n",
       "      <td>338.061688</td>\n",
       "      <td>290.665286</td>\n",
       "      <td>244.182324</td>\n",
       "      <td>212.416530</td>\n",
       "      <td>...</td>\n",
       "      <td>491.562211</td>\n",
       "      <td>453.472541</td>\n",
       "      <td>421.067826</td>\n",
       "      <td>395.365695</td>\n",
       "      <td>378.447954</td>\n",
       "      <td>369.290419</td>\n",
       "      <td>363.885802</td>\n",
       "      <td>362.037312</td>\n",
       "      <td>360.937986</td>\n",
       "      <td>359.936870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_194029_165</th>\n",
       "      <td>4089.551454</td>\n",
       "      <td>4099.503758</td>\n",
       "      <td>4076.524716</td>\n",
       "      <td>4038.705294</td>\n",
       "      <td>3962.634683</td>\n",
       "      <td>3856.468872</td>\n",
       "      <td>3444.100464</td>\n",
       "      <td>3442.939489</td>\n",
       "      <td>3363.027961</td>\n",
       "      <td>3164.719363</td>\n",
       "      <td>...</td>\n",
       "      <td>423.285114</td>\n",
       "      <td>436.143826</td>\n",
       "      <td>508.054026</td>\n",
       "      <td>622.056752</td>\n",
       "      <td>736.905143</td>\n",
       "      <td>805.029935</td>\n",
       "      <td>810.227433</td>\n",
       "      <td>749.567060</td>\n",
       "      <td>658.229602</td>\n",
       "      <td>640.969552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_195108_436</th>\n",
       "      <td>3136.258062</td>\n",
       "      <td>3158.604146</td>\n",
       "      <td>3150.862320</td>\n",
       "      <td>3122.928498</td>\n",
       "      <td>3074.531499</td>\n",
       "      <td>2977.176778</td>\n",
       "      <td>2857.079921</td>\n",
       "      <td>2593.799426</td>\n",
       "      <td>2534.649179</td>\n",
       "      <td>2345.410856</td>\n",
       "      <td>...</td>\n",
       "      <td>710.151501</td>\n",
       "      <td>887.286390</td>\n",
       "      <td>958.044685</td>\n",
       "      <td>879.829818</td>\n",
       "      <td>679.485625</td>\n",
       "      <td>496.435131</td>\n",
       "      <td>466.103091</td>\n",
       "      <td>604.858273</td>\n",
       "      <td>860.001265</td>\n",
       "      <td>1174.676678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_214630_530</th>\n",
       "      <td>5143.751095</td>\n",
       "      <td>5265.341578</td>\n",
       "      <td>5354.983200</td>\n",
       "      <td>5412.049453</td>\n",
       "      <td>5419.047871</td>\n",
       "      <td>5384.352295</td>\n",
       "      <td>5297.645468</td>\n",
       "      <td>5154.911430</td>\n",
       "      <td>4959.021309</td>\n",
       "      <td>4355.826203</td>\n",
       "      <td>...</td>\n",
       "      <td>223.605843</td>\n",
       "      <td>387.514681</td>\n",
       "      <td>640.342330</td>\n",
       "      <td>992.222301</td>\n",
       "      <td>1392.208206</td>\n",
       "      <td>1807.255907</td>\n",
       "      <td>2194.806341</td>\n",
       "      <td>2532.385886</td>\n",
       "      <td>2805.825094</td>\n",
       "      <td>3006.353365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c483_20150901_221141_886</th>\n",
       "      <td>7165.308185</td>\n",
       "      <td>7285.930914</td>\n",
       "      <td>7377.103449</td>\n",
       "      <td>7451.839310</td>\n",
       "      <td>7482.942462</td>\n",
       "      <td>7485.706860</td>\n",
       "      <td>7433.829155</td>\n",
       "      <td>7331.016986</td>\n",
       "      <td>7160.985082</td>\n",
       "      <td>6919.238193</td>\n",
       "      <td>...</td>\n",
       "      <td>115.567154</td>\n",
       "      <td>141.445638</td>\n",
       "      <td>199.326865</td>\n",
       "      <td>296.079572</td>\n",
       "      <td>443.858023</td>\n",
       "      <td>644.318508</td>\n",
       "      <td>901.812133</td>\n",
       "      <td>1227.618439</td>\n",
       "      <td>1607.817198</td>\n",
       "      <td>2037.885017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1448 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ev                                   -3.00        -2.75        -2.50  \\\n",
       "prob 0006_20160721_170707_736     0.003962     0.002357     0.001044   \n",
       "     0006_20160721_175239_909     0.003076     0.002128     0.001229   \n",
       "     0006_20160721_181525_062     0.001954     0.001145     0.000493   \n",
       "     0006_20160722_100126_028     0.004304     0.002890     0.001612   \n",
       "     0006_20160722_100951_201     0.029990     0.028178     0.026405   \n",
       "...                                    ...          ...          ...   \n",
       "mse  c483_20150901_173210_443   396.788974   414.150080   424.499389   \n",
       "     c483_20150901_194029_165  4089.551454  4099.503758  4076.524716   \n",
       "     c483_20150901_195108_436  3136.258062  3158.604146  3150.862320   \n",
       "     c483_20150901_214630_530  5143.751095  5265.341578  5354.983200   \n",
       "     c483_20150901_221141_886  7165.308185  7285.930914  7377.103449   \n",
       "\n",
       "ev                                   -2.25        -2.00        -1.75  \\\n",
       "prob 0006_20160721_170707_736     0.000245     0.000000     0.003001   \n",
       "     0006_20160721_175239_909     0.000516     0.000000     0.000166   \n",
       "     0006_20160721_181525_062     0.000056     0.000000     0.000994   \n",
       "     0006_20160722_100126_028     0.000612     0.000072     0.000000   \n",
       "     0006_20160722_100951_201     0.024777     0.023579     0.023505   \n",
       "...                                    ...          ...          ...   \n",
       "mse  c483_20150901_173210_443   421.893856   407.417568   341.777813   \n",
       "     c483_20150901_194029_165  4038.705294  3962.634683  3856.468872   \n",
       "     c483_20150901_195108_436  3122.928498  3074.531499  2977.176778   \n",
       "     c483_20150901_214630_530  5412.049453  5419.047871  5384.352295   \n",
       "     c483_20150901_221141_886  7451.839310  7482.942462  7485.706860   \n",
       "\n",
       "ev                                   -1.50        -1.25        -1.00  \\\n",
       "prob 0006_20160721_170707_736     0.003095     0.004559     0.008187   \n",
       "     0006_20160721_175239_909     0.000215     0.001071     0.002562   \n",
       "     0006_20160721_181525_062     0.001045     0.002272     0.004109   \n",
       "     0006_20160722_100126_028     0.001337     0.001961     0.004161   \n",
       "     0006_20160722_100951_201     0.023460     0.024971     0.027579   \n",
       "...                                    ...          ...          ...   \n",
       "mse  c483_20150901_173210_443   338.061688   290.665286   244.182324   \n",
       "     c483_20150901_194029_165  3444.100464  3442.939489  3363.027961   \n",
       "     c483_20150901_195108_436  2857.079921  2593.799426  2534.649179   \n",
       "     c483_20150901_214630_530  5297.645468  5154.911430  4959.021309   \n",
       "     c483_20150901_221141_886  7433.829155  7331.016986  7160.985082   \n",
       "\n",
       "ev                                   -0.75  ...        3.75        4.00  \\\n",
       "prob 0006_20160721_170707_736     0.012777  ...    0.042720    0.040976   \n",
       "     0006_20160721_175239_909     0.004685  ...    0.049166    0.049012   \n",
       "     0006_20160721_181525_062     0.006494  ...    0.047626    0.047743   \n",
       "     0006_20160722_100126_028     0.007303  ...    0.046876    0.045750   \n",
       "     0006_20160722_100951_201     0.031080  ...    0.036685    0.036775   \n",
       "...                                    ...  ...         ...         ...   \n",
       "mse  c483_20150901_173210_443   212.416530  ...  491.562211  453.472541   \n",
       "     c483_20150901_194029_165  3164.719363  ...  423.285114  436.143826   \n",
       "     c483_20150901_195108_436  2345.410856  ...  710.151501  887.286390   \n",
       "     c483_20150901_214630_530  4355.826203  ...  223.605843  387.514681   \n",
       "     c483_20150901_221141_886  6919.238193  ...  115.567154  141.445638   \n",
       "\n",
       "ev                                   4.25        4.50         4.75  \\\n",
       "prob 0006_20160721_170707_736    0.038788    0.036664     0.034901   \n",
       "     0006_20160721_175239_909    0.048269    0.046416     0.043465   \n",
       "     0006_20160721_181525_062    0.047628    0.047221     0.046454   \n",
       "     0006_20160722_100126_028    0.043899    0.041213     0.037872   \n",
       "     0006_20160722_100951_201    0.036704    0.036516     0.036200   \n",
       "...                                   ...         ...          ...   \n",
       "mse  c483_20150901_173210_443  421.067826  395.365695   378.447954   \n",
       "     c483_20150901_194029_165  508.054026  622.056752   736.905143   \n",
       "     c483_20150901_195108_436  958.044685  879.829818   679.485625   \n",
       "     c483_20150901_214630_530  640.342330  992.222301  1392.208206   \n",
       "     c483_20150901_221141_886  199.326865  296.079572   443.858023   \n",
       "\n",
       "ev                                    5.00         5.25         5.50  \\\n",
       "prob 0006_20160721_170707_736     0.033377     0.032077     0.031602   \n",
       "     0006_20160721_175239_909     0.040067     0.036753     0.033649   \n",
       "     0006_20160721_181525_062     0.045098     0.042875     0.039709   \n",
       "     0006_20160722_100126_028     0.034099     0.030310     0.026915   \n",
       "     0006_20160722_100951_201     0.035951     0.036021     0.036424   \n",
       "...                                    ...          ...          ...   \n",
       "mse  c483_20150901_173210_443   369.290419   363.885802   362.037312   \n",
       "     c483_20150901_194029_165   805.029935   810.227433   749.567060   \n",
       "     c483_20150901_195108_436   496.435131   466.103091   604.858273   \n",
       "     c483_20150901_214630_530  1807.255907  2194.806341  2532.385886   \n",
       "     c483_20150901_221141_886   644.318508   901.812133  1227.618439   \n",
       "\n",
       "ev                                    5.75         6.00  \n",
       "prob 0006_20160721_170707_736     0.031327     0.030614  \n",
       "     0006_20160721_175239_909     0.030640     0.027636  \n",
       "     0006_20160721_181525_062     0.035463     0.030556  \n",
       "     0006_20160722_100126_028     0.024486     0.023014  \n",
       "     0006_20160722_100951_201     0.036956     0.037334  \n",
       "...                                    ...          ...  \n",
       "mse  c483_20150901_173210_443   360.937986   359.936870  \n",
       "     c483_20150901_194029_165   658.229602   640.969552  \n",
       "     c483_20150901_195108_436   860.001265  1174.676678  \n",
       "     c483_20150901_214630_530  2805.825094  3006.353365  \n",
       "     c483_20150901_221141_886  1607.817198  2037.885017  \n",
       "\n",
       "[1448 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "errors = test_data.data[\"mse\"]\n",
    "err_t = torch.tensor(errors.to_numpy())\n",
    "emax, _ = err_t.max(dim=1, keepdim=True)\n",
    "emin, _ = err_t.min(dim=1, keepdim=True)\n",
    "# err_norm = (err_t - emin) / (emax - emin)\n",
    "# print(emax.shape)\n",
    "# print(err_t.shape)\n",
    "err_inv = emax - err_t\n",
    "error_probabilities = (err_inv / err_inv.sum(dim=1, keepdim=True)).numpy()\n",
    "\n",
    "err_df = pd.DataFrame(error_probabilities, index=errors.index, columns=errors.columns)\n",
    "err_df = pd.concat([err_df, errors], keys=(\"prob\", \"mse\"))\n",
    "err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n",
      "Float64Index([ -3.0, -2.75,  -2.5, -2.25,  -2.0, -1.75,  -1.5, -1.25,  -1.0,\n",
      "              -0.75,  -0.5, -0.25,  0.25,   0.5,  0.75,   1.0,  1.25,   1.5,\n",
      "               1.75,   2.0,  2.25,   2.5,  2.75,   3.0,  3.25,   3.5,  3.75,\n",
      "                4.0,  4.25,   4.5,  4.75,   5.0,  5.25,   5.5,  5.75,   6.0],\n",
      "             dtype='float64', name='ev')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f90601602b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "ind = randint(0, len(err_df.loc[\"prob\"]) - 1)\n",
    "print(ind)\n",
    "s = err_df.loc[\"prob\"].iloc[ind].transpose()\n",
    "y = err_df.loc[\"mse\"].iloc[ind].transpose()\n",
    "x = s.index\n",
    "print(x)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9062de4310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_mse = err_df.loc[\"mse\"].aggregate(\"mean\", axis=0).to_numpy()\n",
    "mse_prob = 1 - (mean_mse / mean_mse.max())\n",
    "plt.scatter(x=errors.columns, y=mean_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IPython.utils import io\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "gpus = \"0\" if torch.cuda.is_available() else None\n",
    "\n",
    "trainer = Trainer(gpus=gpus, progress_bar_refresh_rate=0)\n",
    "\n",
    "\n",
    "def check_for_model(model_type):\n",
    "    name = f\"best_{model_type}.ckpt\"\n",
    "    full_path = MODEL_DIR / name\n",
    "    if full_path.exists():\n",
    "        return full_path\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_test_model(ckpt, model_cls):\n",
    "    model = model_cls.load_from_checkpoint(checkpoint_path=str(ckpt))\n",
    "    model.eval()\n",
    "\n",
    "    #     with io.capture_output(stdout=True, stderr=True) as _captured:\n",
    "    #         test_score = trainer.test(model)[\"test_loss\"]\n",
    "    test_score = 0\n",
    "    return test_score, model.cuda(), ckpt.stem\n",
    "\n",
    "\n",
    "def get_best_model(model_cls, backbone: str, use_saved=True):\n",
    "    potential_model = check_for_model(backbone)\n",
    "    if (potential_model is not None) and use_saved:\n",
    "        print(\"Loading stored best model\")\n",
    "        return load_test_model(potential_model, model_cls)\n",
    "    else:\n",
    "        test_scores = dict()\n",
    "        for ckpt in MODEL_DIR.glob(f\"*{backbone}*.ckpt\"):\n",
    "            test_scores[str(ckpt.stem)] = load_test_model(ckpt, model_cls)\n",
    "\n",
    "        best_score, best_model, best_name = min(\n",
    "            test_scores.values(), key=lambda x: x[0]\n",
    "        )\n",
    "#         (MODEL_DIR / f\"best_{backbone}.ckpt\").symlink_to(\n",
    "#             MODEL_DIR / f\"{best_name}.ckpt\"\n",
    "#         )\n",
    "        return best_score, best_model.cuda(), best_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best models\n",
      "Loading stored best model\n",
      "Loading stored best model\n",
      "Loading stored best model\n",
      "Loading stored best model\n",
      "hist_name='histdhdr-epoch=2-val_loss=3.58' hist_score=0\n",
      "mobile_score=0\n",
      "resnet_score=0\n",
      "squeeze_score=0\n",
      "rcnet_score=0\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from dhdrnet.Dataset import LUTDataset, RCDataset\n",
    "from dhdrnet.histogram_model import HistogramNet\n",
    "from dhdrnet.model import DHDRMobileNet_v3, DHDRSqueezeNet\n",
    "from dhdrnet.reconstruction_model import RCNet\n",
    "from dhdrnet.resnet_model import DHDRResnet\n",
    "\n",
    "seed_everything(19)\n",
    "\n",
    "\n",
    "print(\"finding best models\")\n",
    "rcnet_score, rcnet_model, rc_name = get_best_model(RCNet, \"reconstruction\")\n",
    "mobile_score, mobile_model, mobile_name = get_best_model(DHDRMobileNet_v3, \"mobile_v3\")\n",
    "resnet_score, resnet_model, resnet_name = get_best_model(DHDRResnet, \"resnet\")\n",
    "squeeze_score, squeeze_model, squeeze_name = get_best_model(DHDRSqueezeNet, \"squeeze\")\n",
    "hist_score, hist_model, hist_name = get_best_model(HistogramNet, \"hist\",use_saved=False)\n",
    "\n",
    "print(f\"{hist_name=} {hist_score=}\")\n",
    "print(f\"{mobile_score=}\")\n",
    "print(f\"{resnet_score=}\")\n",
    "print(f\"{squeeze_score=}\")\n",
    "print(f\"{rcnet_score=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from more_itertools import collapse, flatten, one\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "evs = torch.tensor(test_data.evs)\n",
    "\n",
    "\n",
    "def get_ev(evs, indices):\n",
    "    return [evs[i] for i in indices]\n",
    "\n",
    "\n",
    "def get_rec_predictions(model, batch, k=4):\n",
    "    X, y_true, names = batch\n",
    "    y_pred = model(X.to(device))\n",
    "    _, pred_ev_idx = torch.topk(y_pred, k, dim=1)\n",
    "    pred_ev = evs[pred_ev_idx]\n",
    "\n",
    "    true_ev_idx = torch.argmax(y_true, dim=1)\n",
    "    true_ev = evs[true_ev_idx]\n",
    "    return zip(names, pred_ev.numpy(), true_ev.numpy())\n",
    "\n",
    "\n",
    "def get_ce_predictions(model, batch, k=4):\n",
    "    X, y_true_idx, names = batch\n",
    "    y_pred = model(X.to(device))\n",
    "    _, pred_ev_idx = torch.topk(y_pred, k, dim=1)\n",
    "    pred_ev = evs[pred_ev_idx]\n",
    "\n",
    "    true_ev = evs[y_true_idx]\n",
    "    return zip(names, pred_ev.numpy(), true_ev.numpy())\n",
    "\n",
    "\n",
    "def topk_accuracy(model, evaluator, dataloader, k=4):\n",
    "    model.eval()\n",
    "    names, pred_evs, true_evs = zip(\n",
    "        *flatten((evaluator(model, batch, k) for batch in dataloader))\n",
    "    )\n",
    "\n",
    "    c = 0\n",
    "    for predicted_evs, true_ev in zip(pred_evs, true_evs):\n",
    "        if true_ev in predicted_evs:\n",
    "            c += 1\n",
    "\n",
    "    return 100.0 * c / len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from dhdrnet.Dataset import HistogramDataset\n",
    "rc_data = test_data\n",
    "reconstruction_loader = DataLoader(rc_data, batch_size=70, num_workers=8)\n",
    "\n",
    "# rcnet_model = RCNet.load_from_checkpoint(\n",
    "#     str(ROOT_DIR / \"checkpoints\" / \"reconstructiondhdr-epoch=173-val_loss=0.00.ckpt\")\n",
    "# ).to(device)\n",
    "\n",
    "lut_data = LUTDataset(\n",
    "    df=pd.read_csv(ROOT_DIR / \"precomputed_data\" / \"store_current.csv\"),\n",
    "    exposure_path=DATA_DIR / \"correct_exposures\" / \"exposures\",\n",
    "    raw_dir=DATA_DIR / \"dngs\",\n",
    "    name_list=ROOT_DIR / \"precomputed_data\" / \"test_current.csv\",\n",
    "    transform=Compose([Resize((300, 300)), ToTensor()]),\n",
    ")\n",
    "lut_loader = DataLoader(lut_data, batch_size=20, num_workers=8)\n",
    "\n",
    "hist_data = HistogramDataset(\n",
    "    df=pd.read_csv(ROOT_DIR / \"precomputed_data\" / \"store_current.csv\"),\n",
    "    exposure_path=DATA_DIR / \"correct_exposures\" / \"exposures\",\n",
    "    raw_dir=DATA_DIR / \"dngs\",\n",
    "    name_list=ROOT_DIR / \"precomputed_data\" / \"test_current.csv\",\n",
    "    transform=Compose([Resize((300, 300)), ToTensor()]),\n",
    ")\n",
    "hist_loader = DataLoader(hist_data, batch_size=20,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>,\n",
      "            {'HistNet': [0.6906077348066298,\n",
      "                         0.9668508287292817,\n",
      "                         1.1049723756906078,\n",
      "                         1.6574585635359116,\n",
      "                         2.7624309392265194,\n",
      "                         3.1767955801104972,\n",
      "                         3.591160220994475],\n",
      "             'MobileNet-v2': [40.88397790055249,\n",
      "                              66.43646408839778,\n",
      "                              78.31491712707182,\n",
      "                              86.1878453038674,\n",
      "                              90.05524861878453,\n",
      "                              93.23204419889503,\n",
      "                              94.7513812154696],\n",
      "             'ResNet-18': [45.16574585635359,\n",
      "                           68.50828729281768,\n",
      "                           79.00552486187846,\n",
      "                           85.91160220994475,\n",
      "                           89.50276243093923,\n",
      "                           91.43646408839778,\n",
      "                           93.50828729281768],\n",
      "             'SqueezeNet': [42.81767955801105,\n",
      "                            62.70718232044199,\n",
      "                            75.27624309392266,\n",
      "                            81.353591160221,\n",
      "                            84.80662983425414,\n",
      "                            86.04972375690608,\n",
      "                            87.29281767955801]})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "model_loader_pairs = {\n",
    "#     \"Reconstruction\": (rcnet_model, get_rec_predictions, reconstruction_loader),\n",
    "    \"ResNet-18\": (resnet_model, get_ce_predictions, lut_loader),\n",
    "    \"MobileNet-v2\": (mobile_model, get_ce_predictions, lut_loader),\n",
    "    \"SqueezeNet\": (squeeze_model, get_ce_predictions, lut_loader),\n",
    "    \"HistNet\":  (hist_model, get_ce_predictions, hist_loader),\n",
    "}\n",
    "\n",
    "model_topk_scores = defaultdict(list)\n",
    "\n",
    "for k in range(1, 8):\n",
    "    for name, args in model_loader_pairs.items():\n",
    "        score = topk_accuracy(*args, k=k)\n",
    "        model_topk_scores[name].append(score)\n",
    "\n",
    "pprint(model_topk_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "figdir = Path(ROOT_DIR / \"figures\")\n",
    "kdf = pd.DataFrame(model_topk_scores, index=range(1, 8))\n",
    "ax = kdf.plot(\n",
    "    grid=\"both\", title=\"Top-K Accuracy\", xlabel=\"K\", ylabel=\"% Accuracy\", figsize=(5, 5)\n",
    ")\n",
    "# ax.figure.savefig(figdir / \"topk_plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "kdf.to_latex(figdir / \"topk_table.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ok, this is all great stuff, now what about comparing to say random?\n",
    "\n",
    " What do we need to do that?\n",
    "\n",
    " * Test dataset\n",
    " * randomly select an exposure as secondary choice\n",
    " * compare the overall MSE of this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2772.136850072036"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random as rand\n",
    "\n",
    "df = test_data.data\n",
    "# rand_ev = rand.choices(range(0,len(df[\"mse\"].columns)), k=len(df))\n",
    "# df.take(rand_ev,axis=0)\n",
    "rand_sel = dict()\n",
    "for name, data in df.iterrows():\n",
    "    ev = rand.choice(df[\"mse\"].columns)\n",
    "    rand_sel[name] = (ev, data[\"mse\"][ev])\n",
    "\n",
    "\n",
    "mean_err = np.mean([x[1] for x in rand_sel.values()])\n",
    "mean_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "names, mobile_pred_evs, true_evs = zip(\n",
    "    *flatten((get_ce_predictions(mobile_model, batch, k) for batch in lut_loader))\n",
    ")\n",
    "_, resnet_pred_evs, _ = zip(\n",
    "    *flatten((get_ce_predictions(resnet_model, batch, k) for batch in lut_loader))\n",
    ")\n",
    "\n",
    "_, squeeze_pred_evs, _ = zip(\n",
    "    *flatten((get_ce_predictions(squeeze_model, batch, k) for batch in lut_loader))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006_20160721_170707_736</td>\n",
       "      <td>[3.75, 3.5, 3.0, 3.25, 4.0, 2.75, 2.5, 2.0, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006_20160721_175239_909</td>\n",
       "      <td>[3.75, 3.5, 4.0, 3.25, 3.0, 4.25, 2.75, 2.5, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006_20160721_181525_062</td>\n",
       "      <td>[4.0, 3.75, 4.25, 3.5, 4.5, 3.25, 4.75, 3.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006_20160722_100126_028</td>\n",
       "      <td>[3.0, 3.5, 3.75, 3.25, 2.75, 2.5, 4.0, 2.0, 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006_20160722_100951_201</td>\n",
       "      <td>[-0.25, -0.5, -0.75, -1.0, 3.0, 3.5, 4.25, 3.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>c483_20150901_173210_443</td>\n",
       "      <td>[-0.5, -1.0, 4.25, -0.75, -0.25, 4.0, 4.5, 3.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>c483_20150901_194029_165</td>\n",
       "      <td>[4.0, 4.25, 3.75, 4.5, 3.5, 3.25, 4.75, -1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>c483_20150901_195108_436</td>\n",
       "      <td>[4.75, 4.0, 4.25, 4.5, 5.0, 3.0, 3.25, 3.75, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>c483_20150901_214630_530</td>\n",
       "      <td>[3.0, 3.25, 2.75, 2.5, 3.5, 3.75, 2.0, 2.25, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>c483_20150901_221141_886</td>\n",
       "      <td>[3.75, 3.5, 3.25, 3.0, 4.0, 2.75, 2.5, 2.0, 2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        names  \\\n",
       "0    0006_20160721_170707_736   \n",
       "1    0006_20160721_175239_909   \n",
       "2    0006_20160721_181525_062   \n",
       "3    0006_20160722_100126_028   \n",
       "4    0006_20160722_100951_201   \n",
       "..                        ...   \n",
       "719  c483_20150901_173210_443   \n",
       "720  c483_20150901_194029_165   \n",
       "721  c483_20150901_195108_436   \n",
       "722  c483_20150901_214630_530   \n",
       "723  c483_20150901_221141_886   \n",
       "\n",
       "                                                  pred  \n",
       "0    [3.75, 3.5, 3.0, 3.25, 4.0, 2.75, 2.5, 2.0, 2....  \n",
       "1    [3.75, 3.5, 4.0, 3.25, 3.0, 4.25, 2.75, 2.5, 2...  \n",
       "2    [4.0, 3.75, 4.25, 3.5, 4.5, 3.25, 4.75, 3.0, -...  \n",
       "3    [3.0, 3.5, 3.75, 3.25, 2.75, 2.5, 4.0, 2.0, 2....  \n",
       "4    [-0.25, -0.5, -0.75, -1.0, 3.0, 3.5, 4.25, 3.2...  \n",
       "..                                                 ...  \n",
       "719  [-0.5, -1.0, 4.25, -0.75, -0.25, 4.0, 4.5, 3.7...  \n",
       "720  [4.0, 4.25, 3.75, 4.5, 3.5, 3.25, 4.75, -1.0, ...  \n",
       "721  [4.75, 4.0, 4.25, 4.5, 5.0, 3.0, 3.25, 3.75, 3...  \n",
       "722  [3.0, 3.25, 2.75, 2.5, 3.5, 3.75, 2.0, 2.25, 1...  \n",
       "723  [3.75, 3.5, 3.25, 3.0, 4.0, 2.75, 2.5, 2.0, 2....  \n",
       "\n",
       "[724 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_df = pd.DataFrame.from_records(\n",
    "    zip(names, mobile_pred_evs), columns=[\"names\", \"pred\"]\n",
    ")\n",
    "mobile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006_20160721_170707_736</td>\n",
       "      <td>[3.0, 3.25, 3.5, 2.75, 2.5, 3.75, 2.25, 2.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006_20160721_175239_909</td>\n",
       "      <td>[3.5, 3.75, 3.25, 4.0, 3.0, 4.25, 2.75, 4.5, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006_20160721_181525_062</td>\n",
       "      <td>[4.0, 3.75, 4.25, 3.5, 3.25, 4.5, 4.75, 3.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006_20160722_100126_028</td>\n",
       "      <td>[3.25, 3.5, 3.0, 2.75, 3.75, 2.5, 2.25, 4.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006_20160722_100951_201</td>\n",
       "      <td>[-0.5, -0.75, 4.25, -0.25, 4.5, 3.75, 4.0, 5.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>c483_20150901_173210_443</td>\n",
       "      <td>[-0.75, 4.5, -0.5, 4.25, 3.75, 4.0, 5.0, 5.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>c483_20150901_194029_165</td>\n",
       "      <td>[4.25, 4.0, 3.75, 4.5, 3.5, 3.25, 4.75, 5.0, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>c483_20150901_195108_436</td>\n",
       "      <td>[3.0, 4.5, 5.0, 3.25, 4.75, 2.75, 3.5, 5.25, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>c483_20150901_214630_530</td>\n",
       "      <td>[3.25, 3.0, 3.5, 2.75, 2.5, 3.75, 2.25, 4.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>c483_20150901_221141_886</td>\n",
       "      <td>[3.5, 3.75, 3.25, 4.0, 3.0, 2.75, 4.25, 2.5, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  \\\n",
       "0    0006_20160721_170707_736   \n",
       "1    0006_20160721_175239_909   \n",
       "2    0006_20160721_181525_062   \n",
       "3    0006_20160722_100126_028   \n",
       "4    0006_20160722_100951_201   \n",
       "..                        ...   \n",
       "719  c483_20150901_173210_443   \n",
       "720  c483_20150901_194029_165   \n",
       "721  c483_20150901_195108_436   \n",
       "722  c483_20150901_214630_530   \n",
       "723  c483_20150901_221141_886   \n",
       "\n",
       "                                                     1  \n",
       "0    [3.0, 3.25, 3.5, 2.75, 2.5, 3.75, 2.25, 2.0, 4...  \n",
       "1    [3.5, 3.75, 3.25, 4.0, 3.0, 4.25, 2.75, 4.5, 2...  \n",
       "2    [4.0, 3.75, 4.25, 3.5, 3.25, 4.5, 4.75, 3.0, 2...  \n",
       "3    [3.25, 3.5, 3.0, 2.75, 3.75, 2.5, 2.25, 4.0, 4...  \n",
       "4    [-0.5, -0.75, 4.25, -0.25, 4.5, 3.75, 4.0, 5.0...  \n",
       "..                                                 ...  \n",
       "719  [-0.75, 4.5, -0.5, 4.25, 3.75, 4.0, 5.0, 5.5, ...  \n",
       "720  [4.25, 4.0, 3.75, 4.5, 3.5, 3.25, 4.75, 5.0, 5...  \n",
       "721  [3.0, 4.5, 5.0, 3.25, 4.75, 2.75, 3.5, 5.25, 4...  \n",
       "722  [3.25, 3.0, 3.5, 2.75, 2.5, 3.75, 2.25, 4.0, 2...  \n",
       "723  [3.5, 3.75, 3.25, 4.0, 3.0, 2.75, 4.25, 2.5, 4...  \n",
       "\n",
       "[724 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame.from_records(zip(names, resnet_pred_evs))\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006_20160721_170707_736</td>\n",
       "      <td>[3.0, 3.25, 3.5, 2.75, 2.5, 3.75, 2.25, 2.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006_20160721_175239_909</td>\n",
       "      <td>[3.5, 3.75, 3.25, 4.0, 3.0, 4.25, 2.75, 4.5, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006_20160721_181525_062</td>\n",
       "      <td>[4.0, 3.75, 4.25, 3.5, 3.25, 4.5, 4.75, 3.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006_20160722_100126_028</td>\n",
       "      <td>[3.25, 3.5, 3.0, 2.75, 3.75, 2.5, 2.25, 4.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006_20160722_100951_201</td>\n",
       "      <td>[-0.5, -0.75, 4.25, -0.25, 4.5, 3.75, 4.0, 5.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>c483_20150901_173210_443</td>\n",
       "      <td>[-0.75, 4.5, -0.5, 4.25, 3.75, 4.0, 5.0, 5.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>c483_20150901_194029_165</td>\n",
       "      <td>[4.25, 4.0, 3.75, 4.5, 3.5, 3.25, 4.75, 5.0, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>c483_20150901_195108_436</td>\n",
       "      <td>[3.0, 4.5, 5.0, 3.25, 4.75, 2.75, 3.5, 5.25, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>c483_20150901_214630_530</td>\n",
       "      <td>[3.25, 3.0, 3.5, 2.75, 2.5, 3.75, 2.25, 4.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>c483_20150901_221141_886</td>\n",
       "      <td>[3.5, 3.75, 3.25, 4.0, 3.0, 2.75, 4.25, 2.5, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  \\\n",
       "0    0006_20160721_170707_736   \n",
       "1    0006_20160721_175239_909   \n",
       "2    0006_20160721_181525_062   \n",
       "3    0006_20160722_100126_028   \n",
       "4    0006_20160722_100951_201   \n",
       "..                        ...   \n",
       "719  c483_20150901_173210_443   \n",
       "720  c483_20150901_194029_165   \n",
       "721  c483_20150901_195108_436   \n",
       "722  c483_20150901_214630_530   \n",
       "723  c483_20150901_221141_886   \n",
       "\n",
       "                                                     1  \n",
       "0    [3.0, 3.25, 3.5, 2.75, 2.5, 3.75, 2.25, 2.0, 4...  \n",
       "1    [3.5, 3.75, 3.25, 4.0, 3.0, 4.25, 2.75, 4.5, 2...  \n",
       "2    [4.0, 3.75, 4.25, 3.5, 3.25, 4.5, 4.75, 3.0, 2...  \n",
       "3    [3.25, 3.5, 3.0, 2.75, 3.75, 2.5, 2.25, 4.0, 4...  \n",
       "4    [-0.5, -0.75, 4.25, -0.25, 4.5, 3.75, 4.0, 5.0...  \n",
       "..                                                 ...  \n",
       "719  [-0.75, 4.5, -0.5, 4.25, 3.75, 4.0, 5.0, 5.5, ...  \n",
       "720  [4.25, 4.0, 3.75, 4.5, 3.5, 3.25, 4.75, 5.0, 5...  \n",
       "721  [3.0, 4.5, 5.0, 3.25, 4.75, 2.75, 3.5, 5.25, 4...  \n",
       "722  [3.25, 3.0, 3.5, 2.75, 2.5, 3.75, 2.25, 4.0, 2...  \n",
       "723  [3.5, 3.75, 3.25, 4.0, 3.0, 2.75, 4.25, 2.5, 4...  \n",
       "\n",
       "[724 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeeze_df = pd.DataFrame.from_records(zip(names, squeeze_pred_evs))\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>metric</th>\n",
       "      <th>ev</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0030_20151008_105249_589</td>\n",
       "      <td>rmse</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>54.637144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0030_20151008_105249_589</td>\n",
       "      <td>psnr</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>13.381044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030_20151008_105249_589</td>\n",
       "      <td>ssim</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>0.688111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0030_20151008_105249_589</td>\n",
       "      <td>perceptual</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>0.168723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0030_20151008_105249_589</td>\n",
       "      <td>rmse</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>55.133444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001467</th>\n",
       "      <td>6FHF_20150303_115853_902</td>\n",
       "      <td>perceptual</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.077148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001468</th>\n",
       "      <td>6FHF_20150303_115853_902</td>\n",
       "      <td>rmse</td>\n",
       "      <td>6.00</td>\n",
       "      <td>21.963507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001469</th>\n",
       "      <td>6FHF_20150303_115853_902</td>\n",
       "      <td>psnr</td>\n",
       "      <td>6.00</td>\n",
       "      <td>21.296770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001470</th>\n",
       "      <td>6FHF_20150303_115853_902</td>\n",
       "      <td>ssim</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.944107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001471</th>\n",
       "      <td>6FHF_20150303_115853_902</td>\n",
       "      <td>perceptual</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.076567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13001472 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name      metric    ev      score\n",
       "0         0030_20151008_105249_589        rmse -3.00  54.637144\n",
       "1         0030_20151008_105249_589        psnr -3.00  13.381044\n",
       "2         0030_20151008_105249_589        ssim -3.00   0.688111\n",
       "3         0030_20151008_105249_589  perceptual -3.00   0.168723\n",
       "4         0030_20151008_105249_589        rmse -2.75  55.133444\n",
       "...                            ...         ...   ...        ...\n",
       "13001467  6FHF_20150303_115853_902  perceptual  5.75   0.077148\n",
       "13001468  6FHF_20150303_115853_902        rmse  6.00  21.963507\n",
       "13001469  6FHF_20150303_115853_902        psnr  6.00  21.296770\n",
       "13001470  6FHF_20150303_115853_902        ssim  6.00   0.944107\n",
       "13001471  6FHF_20150303_115853_902  perceptual  6.00   0.076567\n",
       "\n",
       "[13001472 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = (\n",
    "    pd.read_csv(ROOT_DIR / \"precomputed_data\" / \"store_2020-10-27.csv\")\n",
    "    .drop(columns=[\"ev1\"])\n",
    "    .rename(columns={\"ev2\": \"ev\"})\n",
    ")\n",
    "test_names = pd.read_csv(ROOT_DIR / \"precomputed_data\" / \"test_current.csv\")\n",
    "\n",
    "score_df = score_df.set_index(\"name\")\n",
    "score_df = score_df.loc[score_df.index.intersection(test_names[\"names\"])]\n",
    "score_df = score_df.reset_index()\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_score_inds(df, score_df):\n",
    "    score_inds = []\n",
    "    names = []\n",
    "    for _ind, (name, preds) in df.iterrows():\n",
    "        scores = score_df[score_df[\"name\"] == name]\n",
    "        for pred in preds:\n",
    "            score_inds.append(scores[scores[\"ev\"] == pred].index.to_numpy())\n",
    "            names.append(name)\n",
    "\n",
    "    score_inds = list(flatten(score_inds))\n",
    "    return score_inds, names\n",
    "\n",
    "\n",
    "def get_scores_for_preds(pred_df, score_df):\n",
    "    score_inds, names = get_score_inds(pred_df, score_df)\n",
    "    return score_df.loc[score_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_preds(pred_str):\n",
    "    splits = pred_str.split(\" \")\n",
    "    return [float(s) for s in splits[1:-1] if len(s) > 0]\n",
    "    \n",
    "rec_df = pd.read_csv(ROOT_DIR / \"precomputed_data\" / \"rec_preds.csv\", index_col=\"index\")\n",
    "mobile_df = pd.read_csv( ROOT_DIR / \"precomputed_data\" / \"mobile_preds.csv\", index_col=\"index\" ) \n",
    "res_df = pd.read_csv(ROOT_DIR / \"precomputed_data\" / \"res_preds.csv\", index_col=\"index\")\n",
    "squeeze_df = pd.read_csv( ROOT_DIR / \"precomputed_data\" / \"squeeze_preds.csv\", index_col=\"index\" )\n",
    "\n",
    "rec_df[\"ev_predictions\"] = rec_df[\"ev_predictions\"].apply(parse_preds)\n",
    "res_df[\"ev_predictions\"] = res_df[\"ev_predictions\"].apply(parse_preds)\n",
    "mobile_df[\"ev_predictions\"] = mobile_df[\"ev_predictions\"].apply(parse_preds)\n",
    "squeeze_df[\"ev_predictions\"] = squeeze_df[\"ev_predictions\"].apply(parse_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "res_scores = get_scores_for_preds(res_df, score_df)\n",
    "rec_scores = get_scores_for_preds(rec_df, score_df)\n",
    "mobile_scores = get_scores_for_preds(mobile_df, score_df)\n",
    "squeeze_scores = get_scores_for_preds(squeeze_df, score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>perceptual</th>\n",
       "      <td>0.077721</td>\n",
       "      <td>0.064361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psnr</th>\n",
       "      <td>22.808591</td>\n",
       "      <td>4.256144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.155840</td>\n",
       "      <td>0.115419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssim</th>\n",
       "      <td>0.922325</td>\n",
       "      <td>0.108048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean       std\n",
       "metric                         \n",
       "perceptual   0.077721  0.064361\n",
       "psnr        22.808591  4.256144\n",
       "rmse         0.155840  0.115419\n",
       "ssim         0.922325  0.108048"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_scores.groupby(\"metric\").describe()[\"score\"][[\"mean\", \"std\"]].to_latex(\n",
    "    figdir / \"res_scores.tex\"\n",
    ")\n",
    "res_scores.groupby(\"metric\").describe()[\"score\"][[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>perceptual</th>\n",
       "      <td>0.105286</td>\n",
       "      <td>0.107679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psnr</th>\n",
       "      <td>21.858584</td>\n",
       "      <td>5.553252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.196763</td>\n",
       "      <td>0.188101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssim</th>\n",
       "      <td>0.873693</td>\n",
       "      <td>0.203019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean       std\n",
       "metric                         \n",
       "perceptual   0.105286  0.107679\n",
       "psnr        21.858584  5.553252\n",
       "rmse         0.196763  0.188101\n",
       "ssim         0.873693  0.203019"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_scores.groupby(\"metric\").describe()[\"score\"][[\"mean\", \"std\"]].to_latex(\n",
    "    figdir / \"mobile_scores.tex\"\n",
    ")\n",
    "mobile_scores.groupby(\"metric\").describe()[\"score\"][[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>perceptual</th>\n",
       "      <td>0.092211</td>\n",
       "      <td>0.093205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psnr</th>\n",
       "      <td>22.091110</td>\n",
       "      <td>4.556032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.174835</td>\n",
       "      <td>0.146687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssim</th>\n",
       "      <td>0.910201</td>\n",
       "      <td>0.146108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean       std\n",
       "metric                         \n",
       "perceptual   0.092211  0.093205\n",
       "psnr        22.091110  4.556032\n",
       "rmse         0.174835  0.146687\n",
       "ssim         0.910201  0.146108"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeeze_scores.groupby(\"metric\").describe()[\"score\"][[\"mean\", \"std\"]].to_latex(\n",
    "    figdir / \"squeeze_scores.tex\"\n",
    ")\n",
    "squeeze_scores.groupby(\"metric\").describe()[\"score\"][[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DHDRNet",
   "language": "python",
   "name": "dhdrnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "name": "NN Evals.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
