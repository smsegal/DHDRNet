#+TITLE: Test Tables and such
#+PROPERTY: header-args :async yes :session py
# /jpy::84289601f8c10c7ce585a4e69bf5ab7353f755f149807129

* Testing Converting the Errors to Probabilities
#+BEGIN_SRC jupyter-python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

from dhdrnet.util import DATA_DIR, ROOT_DIR

print(DATA_DIR)
#+END_SRC

#+RESULTS:
: /home/shane/Development/DHDRNet/data

#+BEGIN_SRC jupyter-python
from dhdrnet.Dataset import RCDataset

from torchvision.transforms import (
    Compose,
    Resize,
    ToTensor,
)

test_data = RCDataset(
    df=pd.read_csv(ROOT_DIR / "precomputed_data" / "store_current.csv"),
    exposure_path=DATA_DIR / "correct_exposures" / "exposures",
    raw_dir=DATA_DIR / "dngs",
    name_list=ROOT_DIR / "precomputed_data" / "test_current.csv",
    transform=Compose([Resize((300, 300)), ToTensor()]),
)
test_data.data.iloc[0]
#+END_SRC

#+RESULTS:
#+begin_example
metric  ev
mse     -3.00    1564.444742
        -2.75    1620.747432
        -2.50    1666.827206
        -2.25    1694.827552
        -2.00    1703.434451
                    ...
ssim     5.00       0.935391
         5.25       0.933572
         5.50       0.932935
         5.75       0.932762
         6.00       0.931905
Name: 0006_20160721_170707_736, Length: 108, dtype: float64
#+end_example

So I believe I just want to minimize the predicted probabilities as they correspond to these errors.

#+BEGIN_SRC jupyter-python
import torch.nn.functional as F
import torch

errors = test_data.data["mse"]
err_t = torch.tensor(errors.to_numpy())
emax, _ = err_t.max(dim=1, keepdim=True)
emin, _ = err_t.min(dim=1, keepdim=True)
# err_norm = (err_t - emin) / (emax - emin)
# print(emax.shape)
# print(err_t.shape)
err_inv = emax - err_t
error_probabilities = (err_inv / err_inv.sum(dim=1, keepdim=True)).numpy()

err_df = pd.DataFrame(error_probabilities, index=errors.index, columns=errors.columns)
err_df = pd.concat([err_df, errors], keys=("prob", "mse"))
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
x = 100 * torch.rand(3, 10)

xmax, _ = x.max(dim=1, keepdim=True)
inv = (xmax - x)
inv_prob = inv / inv.sum(dim=1,keepdim=True)
print(x)
print(inv_prob)
#+END_SRC

#+RESULTS:
#+begin_example
tensor([[34.8863, 64.8487, 97.5512, 11.6118, 29.5682, 51.3822, 18.5122, 90.1710,
         79.2257, 96.5870],
        [29.1312, 79.1191, 70.5082, 38.8581, 54.2011, 29.6890, 18.1676, 54.6738,
         63.3873,  0.8101],
        [50.2965, 96.3907, 73.2642, 17.8870, 20.7448, 37.8812,  2.1352, 66.8455,
         20.7351, 55.2893]])
tensor([[0.1562, 0.0815, 0.0000, 0.2142, 0.1695, 0.1151, 0.1970, 0.0184, 0.0457,
         0.0024],
        [0.1418, 0.0000, 0.0244, 0.1142, 0.0707, 0.1402, 0.1728, 0.0693, 0.0446,
         0.2221],
        [0.0882, 0.0000, 0.0443, 0.1503, 0.1448, 0.1120, 0.1804, 0.0566, 0.1448,
         0.0787]])
#+end_example


#+BEGIN_SRC jupyter-python
s = err_df.loc["prob"].iloc[1].transpose()
y = err_df.loc["mse"].iloc[1].transpose()
x = s.index
print(x)
plt.scatter(x, y, 10 / (1 - 10*s))
#+END_SRC

#+RESULTS:
:RESULTS:
: Float64Index([ -3.0, -2.75,  -2.5, -2.25,  -2.0, -1.75,  -1.5, -1.25,  -1.0,
:               -0.75,  -0.5, -0.25,  0.25,   0.5,  0.75,   1.0,  1.25,   1.5,
:                1.75,   2.0,  2.25,   2.5,  2.75,   3.0,  3.25,   3.5,  3.75,
:                 4.0,  4.25,   4.5,  4.75,   5.0,  5.25,   5.5,  5.75,   6.0],
:              dtype='float64', name='ev')
: <matplotlib.collections.PathCollection at 0x7fb4f716ec40>
[[file:./.ob-jupyter/56560a96df6e20f70b64f853bca526dfd39f0b0c.png]]
:END:

#+BEGIN_SRC jupyter-python
mean_mse = err_df.loc["mse"].aggregate("mean", axis=0).to_numpy()
mse_prob = 1 - (mean_mse / mean_mse.max())
plt.scatter(x=errors.columns, y=F.softmax(torch.tensor(mse_prob),dim=0))
#+END_SRC

#+RESULTS:
:RESULTS:
: <matplotlib.collections.PathCollection at 0x7fb4f5862f70>
[[file:./.ob-jupyter/be8b74901ac258ffb3e6fb5add2e59e76397f938.png]]
:END:

* Testing Reconstruction model trained with above probabilities

First things first, load the model:
#+BEGIN_SRC jupyter-python
from IPython.utils import io
from pytorch_lightning import Trainer

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
gpus = "0" if torch.cuda.is_available() else None


def get_best_model(model_cls, backbone: str):

    with io.capture_output(stdout=True, stderr=True) as _captured:
        trainer = Trainer(gpus=gpus, progress_bar_refresh_rate=0)
        test_scores = dict()
        for ckpt in (ROOT_DIR / "checkpoints").glob(f"*{backbone}*.ckpt"):
            model = model_cls.load_from_checkpoint(checkpoint_path=str(ckpt))
            model.eval()

            test_score = trainer.test(model)["test_loss"]
            test_scores[str(ckpt.stem)] = test_score, model, ckpt.stem

    best_model = min(test_scores.values(), key=lambda x: x[0])
    return best_model
#+END_SRC

#+RESULTS:

This has been run once so no need to do it again, we have the saved name for the model now
#+BEGIN_SRC jupyter-python
from dhdrnet.reconstruction_model import RCNet
from dhdrnet.histogram_model import HistogramNet
from dhdrnet.model import DHDRMobileNet_v3, DHDRSqueezeNet
from dhdrnet.resnet_model import DHDRResnet
from dhdrnet.Dataset import LUTDataset, RCDataset
from pytorch_lightning import seed_everything


seed_everything(19)

# trainer = Trainer(gpus=gpus)
# name = "dhdr_reconstruction_final2020-09-15T17:39:29.915663"
# rcnet_model = RCNet.load_from_checkpoint(
#     checkpoint_path=str(ROOT_DIR / "checkpoints" / f"{name}.ckpt")
# ).to(device)

rcnet_score, rcnet_model, rc_name = get_best_model(RCNet, "reconstruction")
mobile_score, mobile_model, mobile_name = get_best_model(DHDRMobileNet_v3, "mobile_v3")
resnet_score, resnet_model, resnet_name = get_best_model(DHDRResnet, "resnet")
squeeze_score, squeeze_model, squeeze_name = get_best_model(DHDRSqueezeNet, "squeeze")
print(f"{mobile_score=}")
print(f"{resnet_score=}")
print(f"{squeeze_score=}")
#+END_SRC

#+RESULTS:
#+begin_example
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
mobile_score=1.52499258518219
resnet_score=1.5463569164276123
squeeze_score=1.6655139923095703
#+end_example
Let's get some predictions out of the model and evaluate it.

#+BEGIN_SRC jupyter-python
from torch.utils.data import DataLoader
from more_itertools import flatten, one, collapse

evs = torch.tensor(test_data.evs)


def get_ev(evs, indices):
    return [evs[i] for i in indices]


def get_rec_predictions(model, batch, k=4):
    X, y_true, names = batch
    y_pred = model(X.to(device))
    _, pred_ev_idx = torch.topk(y_pred, k, dim=1)
    pred_ev = evs[pred_ev_idx]

    true_ev_idx = torch.argmax(y_true, dim=1)
    true_ev = evs[true_ev_idx]
    return zip(names, pred_ev.numpy(), true_ev.numpy())


def get_ce_predictions(model, batch, k=4):
    X, y_true_idx, names = batch
    y_pred = model(X.to(device))
    _, pred_ev_idx = torch.topk(y_pred, k, dim=1)
    pred_ev = evs[pred_ev_idx]

    true_ev = evs[y_true_idx]
    return zip(names, pred_ev.numpy(), true_ev.numpy())
#+END_SRC

#+RESULTS:


The idea here is to get the percentage of top-k that contains the right answer,
and the mean distance between the answers and the true ev
#+BEGIN_SRC jupyter-python
def topk_accuracy(model, evaluator, dataloader, k=4):
    model.eval()
    names, pred_evs, true_evs = zip(
        *flatten((evaluator(model, batch, k) for batch in dataloader))
    )

    c = 0
    for predicted_evs, true_ev in zip(pred_evs, true_evs):
        if true_ev in predicted_evs:
            c += 1

    return 100.0 * c / len(names)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
rc_data = test_data
reconstruction_loader = DataLoader(rc_data, batch_size=70, num_workers=8)

rcnet_model = RCNet.load_from_checkpoint(
    str(ROOT_DIR / "checkpoints" / "reconstructiondhdr-epoch=173-val_loss=0.00.ckpt")
).to(device)

lut_data = LUTDataset(
    df=pd.read_csv(ROOT_DIR / "precomputed_data" / "store_current.csv"),
    exposure_path=DATA_DIR / "correct_exposures" / "exposures",
    raw_dir=DATA_DIR / "dngs",
    name_list=ROOT_DIR / "precomputed_data" / "test_current.csv",
    transform=Compose([Resize((300, 300)), ToTensor()]),
)
lut_loader = DataLoader(lut_data, batch_size=70, num_workers=8)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
from collections import defaultdict
from pprint import pprint

model_loader_pairs = {
  "Reconstruction": (rcnet_model,   get_rec_predictions, reconstruction_loader),
  "ResNet-18":      (resnet_model,  get_ce_predictions,  lut_loader),
  "MobileNet-v2":   (mobile_model,  get_ce_predictions,  lut_loader),
  "SqueezeNet":     (squeeze_model, get_ce_predictions,  lut_loader),
}

model_topk_scores = defaultdict(list)

for k in range(1, 8):
    for name, args in model_loader_pairs.items():
        score = topk_accuracy(*args, k=k)
        model_topk_scores[name].append(score)

pprint(model_topk_scores)
#+END_SRC

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-30-32c8a84ddc86> in <module>
     13 for k in range(1, 8):
     14     for name, args in model_loader_pairs.items():
---> 15         score = topk_accuracy(*args, k=k)
     16         model_topk_scores[name].append(score)
     17

<ipython-input-18-b8c0ca167dfc> in topk_accuracy(model, evaluator, dataloader, k)
      1 def topk_accuracy(model, evaluator, dataloader, k=4):
      2     model.eval()
----> 3     names, pred_evs, true_evs = zip(
      4         *flatten((evaluator(model, batch, k) for batch in dataloader))
      5     )

<ipython-input-18-b8c0ca167dfc> in <genexpr>(.0)
      2     model.eval()
      3     names, pred_evs, true_evs = zip(
----> 4         *flatten((evaluator(model, batch, k) for batch in dataloader))
      5     )
      6

<ipython-input-9-fd9eb7c4e4cf> in get_rec_predictions(model, batch, k)
     11 def get_rec_predictions(model, batch, k=4):
     12     X, y_true, names = batch
---> 13     y_pred = model(X.to(device))
     14     _, pred_ev_idx = torch.topk(y_pred, k, dim=1)
     15     pred_ev = evs[pred_ev_idx]

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    548             result = self._slow_forward(*input, **kwargs)
    549         else:
--> 550             result = self.forward(*input, **kwargs)
    551         for hook in self._forward_hooks.values():
    552             hook_result = hook(self, input, result)

~/Development/DHDRNet/dhdrnet/reconstruction_model.py in forward(self, x)
     59
     60     def forward(self, x):
---> 61         x = self.feature_extractor(x)
     62         return x
     63

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    548             result = self._slow_forward(*input, **kwargs)
    549         else:
--> 550             result = self.forward(*input, **kwargs)
    551         for hook in self._forward_hooks.values():
    552             hook_result = hook(self, input, result)

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torchvision/models/mobilenet.py in forward(self, x)
    158
    159     def forward(self, x):
--> 160         return self._forward_impl(x)
    161
    162

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torchvision/models/mobilenet.py in _forward_impl(self, x)
    151         # This exists since TorchScript doesn't support inheritance, so the superclass method
    152         # (this one) needs to have a name other than `forward` that can be accessed in a subclass
--> 153         x = self.features(x)
    154         # Cannot use "squeeze" as batch-size can be 1 => must use reshape with x.shape[0]
    155         x = nn.functional.adaptive_avg_pool2d(x, 1).reshape(x.shape[0], -1)

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    548             result = self._slow_forward(*input, **kwargs)
    549         else:
--> 550             result = self.forward(*input, **kwargs)
    551         for hook in self._forward_hooks.values():
    552             hook_result = hook(self, input, result)

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/container.py in forward(self, input)
     98     def forward(self, input):
     99         for module in self:
--> 100             input = module(input)
    101         return input
    102

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    548             result = self._slow_forward(*input, **kwargs)
    549         else:
--> 550             result = self.forward(*input, **kwargs)
    551         for hook in self._forward_hooks.values():
    552             hook_result = hook(self, input, result)

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/container.py in forward(self, input)
     98     def forward(self, input):
     99         for module in self:
--> 100             input = module(input)
    101         return input
    102

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    548             result = self._slow_forward(*input, **kwargs)
    549         else:
--> 550             result = self.forward(*input, **kwargs)
    551         for hook in self._forward_hooks.values():
    552             hook_result = hook(self, input, result)

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/conv.py in forward(self, input)
    351
    352     def forward(self, input):
--> 353         return self._conv_forward(input, self.weight)
    354
    355 class Conv3d(_ConvNd):

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/nn/modules/conv.py in _conv_forward(self, input, weight)
    347                             weight, self.bias, self.stride,
    348                             _pair(0), self.dilation, self.groups)
--> 349         return F.conv2d(input, weight, self.bias, self.stride,
    350
self.padding, self.dilation, self.groups)
    351

RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
#+end_example
:END:

#+BEGIN_SRC jupyter-python
kdf = pd.DataFrame(model_topk_scores, index=range(1,8))
kdf.plot()
#+END_SRC

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-31-05ba3d2f75ce> in <module>
      1 kdf = pd.DataFrame(model_topk_scores, index=range(1,8))
----> 2 kdf.plot()

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/pandas/plotting/_core.py in __call__(self, *args, **kwargs)
    947                     data.columns = label_name
    948
--> 949         return plot_backend.plot(data, kind=kind, **kwargs)
    950
    951     __call__.__doc__ = __doc__

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/pandas/plotting/_matplotlib/__init__.py in plot(data, kind, **kwargs)
     59             kwargs["ax"] = getattr(ax, "left_ax", ax)
     60     plot_obj = PLOT_CLASSES[kind](data, **kwargs)
---> 61     plot_obj.generate()
     62     plot_obj.draw()
     63     return plot_obj.result

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py in generate(self)
    267     def generate(self):
    268         self._args_adjust()
--> 269         self._compute_plot_data()
    270         self._setup_subplots()
    271         self._make_plot()

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py in _compute_plot_data(self)
    416         # no non-numeric frames or series allowed
    417         if is_empty:
--> 418             raise TypeError("no numeric data to plot")
    419
    420         # GH25587: cast ExtensionArray of pandas (IntegerArray, etc.) to

TypeError: no numeric data to plot
#+end_example
:END:
