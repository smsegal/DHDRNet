#+TITLE: Test Tables and such
#+PROPERTY: header-args :async yes :session /jpy::84289601f8c10c7ce585a4e69bf5ab7353f755f149807129

* Testing Converting the Errors to Probabilities
#+BEGIN_SRC jupyter-python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

from dhdrnet.util import DATA_DIR, ROOT_DIR

print(DATA_DIR)
#+END_SRC

#+RESULTS:
: /home/shane/Development/DHDRNet/data

#+BEGIN_SRC jupyter-python
from dhdrnet.Dataset import RCDataset

from torchvision.transforms import (
    Compose,
    Resize,
    ToTensor,
)

test_data = RCDataset(
    df=pd.read_csv(ROOT_DIR / "precomputed_data" / "store_current.csv"),
    exposure_path=DATA_DIR / "correct_exposures" / "exposures",
    raw_dir=DATA_DIR / "dngs",
    name_list=ROOT_DIR / "precomputed_data" / "test_current.csv",
    transform=Compose([Resize((300, 300)), ToTensor()]),
)
test_data.data.iloc[0]
#+END_SRC

#+RESULTS:
#+begin_example
metric  ev
mse     -3.00    1564.444742
        -2.75    1620.747432
        -2.50    1666.827206
        -2.25    1694.827552
        -2.00    1703.434451
                    ...
ssim     5.00       0.935391
         5.25       0.933572
         5.50       0.932935
         5.75       0.932762
         6.00       0.931905
Name: 0006_20160721_170707_736, Length: 108, dtype: float64
#+end_example

So I believe I just want to minimize the predicted probabilities as they correspond to these errors.

#+BEGIN_SRC jupyter-python
import torch.nn.functional as F
import torch

errors = test_data.data["mse"]
err_t = torch.tensor(errors.to_numpy())
emax, _ = err_t.max(dim=1, keepdim=True)
emin, _ = err_t.min(dim=1, keepdim=True)
# err_norm = (err_t - emin) / (emax - emin)
# print(emax.shape)
# print(err_t.shape)
err_inv = emax - err_t
error_probabilities = (err_inv / err_inv.sum(dim=1, keepdim=True)).numpy()

err_df = pd.DataFrame(error_probabilities, index=errors.index, columns=errors.columns)
err_df = pd.concat([err_df, errors], keys=("prob", "mse"))
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
x = 100 * torch.rand(3, 10)

xmax, _ = x.max(dim=1, keepdim=True)
inv = (xmax - x)
inv_prob = inv / inv.sum(dim=1,keepdim=True)
print(x)
print(inv_prob)
#+END_SRC

#+RESULTS:
#+begin_example
tensor([[66.5910, 69.2041, 27.2806, 61.0278, 97.7251, 23.3812,  5.6667, 76.9371,
         80.4593, 84.2469],
        [96.5479, 63.3671, 60.4586,  7.6775, 83.2170, 54.8003,  3.6124, 22.1430,
         36.0411,  8.0842],
        [84.8353,  7.6244, 14.9038,  4.6812, 44.6573, 70.7590, 30.0510, 72.6739,
         73.4454, 25.6744]])
tensor([[0.0809, 0.0741, 0.1831, 0.0954, 0.0000, 0.1932, 0.2393, 0.0540, 0.0449,
         0.0350],
        [0.0000, 0.0627, 0.0682, 0.1678, 0.0252, 0.0788, 0.1755, 0.1405, 0.1143,
         0.1671],
        [0.0000, 0.1843, 0.1669, 0.1913, 0.0959, 0.0336, 0.1307, 0.0290, 0.0272,
         0.1412]])
#+end_example


#+BEGIN_SRC jupyter-python
s = err_df.loc["prob"].iloc[1].transpose()
y = err_df.loc["mse"].iloc[1].transpose()
x = s.index
print(x)
plt.scatter(x, y, 10 / (1 - 10*s))
#+END_SRC

#+RESULTS:
:RESULTS:
: Float64Index([ -3.0, -2.75,  -2.5, -2.25,  -2.0, -1.75,  -1.5, -1.25,  -1.0,
:               -0.75,  -0.5, -0.25,  0.25,   0.5,  0.75,   1.0,  1.25,   1.5,
:                1.75,   2.0,  2.25,   2.5,  2.75,   3.0,  3.25,   3.5,  3.75,
:                 4.0,  4.25,   4.5,  4.75,   5.0,  5.25,   5.5,  5.75,   6.0],
:              dtype='float64', name='ev')
: <matplotlib.collections.PathCollection at 0x7fdeee375640>
:END:

#+BEGIN_SRC jupyter-python
mean_mse = err_df.loc["mse"].aggregate("mean", axis=0).to_numpy()
mse_prob = 1 - (mean_mse / mean_mse.max())
plt.scatter(x=errors.columns, y=F.softmax(torch.tensor(mse_prob),dim=0))
#+END_SRC

#+RESULTS:
:RESULTS:
: <matplotlib.collections.PathCollection at 0x7fdef483e4f0>
[[file:./.ob-jupyter/be8b74901ac258ffb3e6fb5add2e59e76397f938.png]]
:END:

* Testing Reconstruction model trained with above probabilities

First things first, load the model:
#+BEGIN_SRC jupyter-python
from IPython.utils import io
from pytorch_lightning import Trainer

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
gpus = "0" if torch.cuda.is_available() else None


def get_best_model(model_cls, backbone: str):

    with io.capture_output(stdout=True, stderr=True) as _captured:
        trainer = Trainer(gpus=gpus, progress_bar_refresh_rate=0)
        test_scores = dict()
        for ckpt in (ROOT_DIR / "checkpoints").glob(f"*{backbone}*"):
            model = model_cls.load_from_checkpoint(checkpoint_path=str(ckpt))
            model.eval()

            test_score = trainer.test(model)["test_loss"]
            test_scores[str(ckpt.stem)] = test_score, model, ckpt.stem

    best_model = min(test_scores.values(), key=lambda x: x[0])
    return best_model
#+END_SRC

#+RESULTS:

This has been run once so no need to do it again, we have the saved name for the model now
#+BEGIN_SRC jupyter-python
from dhdrnet.reconstruction_model import RCNet
from dhdrnet.histogram_model import HistogramNet
from dhdrnet.model import DHDRMobileNet_v3, DHDRSqueezeNet
from dhdrnet.resnet_model import DHDRResnet
from dhdrnet.Dataset import LUTDataset, RCDataset
from pytorch_lightning import seed_everything


seed_everything(19)

# trainer = Trainer(gpus=gpus)
# name = "dhdr_reconstruction_final2020-09-15T17:39:29.915663"
# rcnet_model = RCNet.load_from_checkpoint(
#     checkpoint_path=str(ROOT_DIR / "checkpoints" / f"{name}.ckpt")
# ).to(device)

rcnet_score, rcnet_model, rc_name = get_best_model(RCNet, "reconsctruction")
mobile_score, mobile_model, mobile_name = get_best_model(DHDRMobileNet_v3, "mobile_v3")
resnet_score, resnet_model, resnet_name = get_best_model(DHDRResnet, "resnet")
squeeze_score, squeeze_model, squeeze_name = get_best_model(DHDRSqueezeNet, "squeeze")
print(f"{mobile_score=}")
print(f"{resnet_score=}")
print(f"{squeeze_score=}")
#+END_SRC

#+RESULTS:
#+begin_example
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
mobile_score=1.519905924797058
resnet_score=1.5426706075668335
squeeze_score=1.6619364023208618
#+end_example
Let's get some predictions out of the model and evaluate it.

#+BEGIN_SRC jupyter-python
from torch.utils.data import DataLoader
from more_itertools import flatten, one, collapse

evs = torch.tensor(test_data.evs)


def get_ev(evs, indices):
    return [evs[i] for i in indices]


def get_rec_predictions(model, batch, k=4):
    X, y_true, names = batch
    y_pred = model(X.to(device))
    _, pred_ev_idx = torch.topk(y_pred, k, dim=1)
    pred_ev = evs[pred_ev_idx]

    true_ev_idx = torch.argmax(y_true, dim=1)
    true_ev = evs[true_ev_idx]
    return zip(names, pred_ev.numpy(), true_ev.numpy())


def get_ce_predictions(model, batch, k=4):
    X, y_true_idx, names = batch
    y_pred = model(X.to(device))
    _, pred_ev_idx = torch.topk(y_pred, k, dim=1)
    pred_ev = evs[pred_ev_idx]

    true_ev = evs[y_true_idx]
    return zip(names, pred_ev.numpy(), true_ev.numpy())
#+END_SRC

#+RESULTS:


The idea here is to get the percentage of top-k that contains the right answer,
and the mean distance between the answers and the true ev
#+BEGIN_SRC jupyter-python
def topk_accuracy(model, evaluator, dataloader, k=4):
    model.eval()
    names, pred_evs, true_evs = zip(
        *flatten((evaluator(model, batch, k) for batch in dataloader))
    )

    c = 0
    for predicted_evs, true_ev in zip(pred_evs, true_evs):
        if true_ev in predicted_evs:
            c += 1

    return f"{100*c / len(names):.2f}%"
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
rc_data = test_data
reconstruction_loader = DataLoader(rc_data, batch_size=70, num_workers=8)

lut_data = LUTDataset(
    df=pd.read_csv(ROOT_DIR / "precomputed_data" / "store_current.csv"),
    exposure_path=DATA_DIR / "correct_exposures" / "exposures",
    raw_dir=DATA_DIR / "dngs",
    name_list=ROOT_DIR / "precomputed_data" / "test_current.csv",
    transform=Compose([Resize((300, 300)), ToTensor()]),
)
lut_loader = DataLoader(lut_data, batch_size=70, num_workers=8)

#+END_SRC

#+RESULTS:


#+BEGIN_SRC jupyter-python
rc_acc = topk_accuracy(rcnet_model, get_rec_predictions, reconstruction_loader, k=3)
resnet_acc = topk_accuracy(resnet_model, get_ce_predictions, lut_loader, k=3)
mobile_acc = topk_accuracy(mobile_model, get_ce_predictions, lut_loader, k=3)
squeeze_acc = topk_accuracy(squeeze_model, get_ce_predictions, lut_loader, k=3)

print(f"{rc_acc=}")
print(f"{resnet_acc=}")
print(f"{mobile_acc=}")
print(f"{squeeze_acc=}")
#+END_SRC

#+RESULTS:
: rc_acc='25.28%'
: resnet_acc='80.80%'
: mobile_acc='77.76%'
: squeeze_acc='75.41%'
