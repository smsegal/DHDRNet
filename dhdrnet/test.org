#+TITLE: Test Tables and such
#+PROPERTY: header-args :async yes :session /jpy::

* Testing Converting the Errors to Probabilities
#+BEGIN_SRC jupyter-python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

from dhdrnet.util import DATA_DIR, ROOT_DIR

print(DATA_DIR)
#+END_SRC

#+RESULTS:
: /home/shane/Development/DHDRNet/data

#+BEGIN_SRC jupyter-python
from dhdrnet.Dataset import RCDataset

from torchvision.transforms import (
    Compose,
    Resize,
    ToTensor,
)

test_data = RCDataset(
    df=pd.read_csv(ROOT_DIR / "precomputed_data" / "store_current.csv"),
    exposure_path=DATA_DIR / "correct_exposures" / "exposures",
    raw_dir=DATA_DIR / "dngs",
    name_list=ROOT_DIR / "precomputed_data" / "test_current.csv",
    transform=Compose([Resize((300, 300)), ToTensor()]),
)
test_data.data.iloc[0]
#+END_SRC

#+RESULTS:
#+begin_example
metric  ev
mse     -3.00    1564.444742
        -2.75    1620.747432
        -2.50    1666.827206
        -2.25    1694.827552
        -2.00    1703.434451
                    ...
ssim     5.00       0.935391
         5.25       0.933572
         5.50       0.932935
         5.75       0.932762
         6.00       0.931905
Name: 0006_20160721_170707_736, Length: 108, dtype: float64
#+end_example

So I believe I just want to minimize the predicted probabilities as they correspond to these errors.

#+BEGIN_SRC jupyter-python
import torch.nn.functional as F
import torch

errors = test_data.data["mse"]
err_t = torch.tensor(errors.to_numpy())
emax, _ = err_t.max(dim=1, keepdim=True)
emin, _ = err_t.min(dim=1, keepdim=True)
# err_norm = (err_t - emin) / (emax - emin)
# print(emax.shape)
# print(err_t.shape)
err_inv = emax - err_t
error_probabilities = (err_inv / err_inv.sum(dim=1, keepdim=True)).numpy()

err_df = pd.DataFrame(error_probabilities, index=errors.index, columns=errors.columns)
err_df = pd.concat([err_df, errors], keys=("prob", "mse"))
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
x = 100 * torch.rand(3, 10)

xmax, _ = x.max(dim=1, keepdim=True)
inv = (xmax - x)
inv_prob = inv / inv.sum(dim=1,keepdim=True)
print(x)
print(inv_prob)
#+END_SRC

#+RESULTS:
#+begin_example
tensor([[74.1587, 82.7843, 10.8144, 22.1201, 17.0481, 25.2346, 17.0551, 21.8748,
          3.8643, 66.4096],
        [46.8657, 28.4840, 16.3497, 59.6351, 51.8695, 39.1494, 57.8994, 46.3365,
          0.3531, 62.9342],
        [16.6854, 65.8373,  9.8939, 37.0860, 42.2633, 29.1208,  6.4745,  7.9376,
         99.5067, 41.2477]])
tensor([[0.0177, 0.0000, 0.1479, 0.1247, 0.1351, 0.1183, 0.1351, 0.1252, 0.1622,
         0.0337],
        [0.0732, 0.1570, 0.2123, 0.0150, 0.0504, 0.1084, 0.0229, 0.0756, 0.2852,
         0.0000],
        [0.1296, 0.0527, 0.1402, 0.0977, 0.0896, 0.1101, 0.1456, 0.1433, 0.0000,
         0.0912]])
#+end_example


#+BEGIN_SRC jupyter-python
s = err_df.loc["prob"].iloc[1].transpose()
y = err_df.loc["mse"].iloc[1].transpose()
x = s.index
print(x)
plt.scatter(x, y, 10 / (1 - 10*s))
#+END_SRC

#+RESULTS:
:RESULTS:
: Float64Index([ -3.0, -2.75,  -2.5, -2.25,  -2.0, -1.75,  -1.5, -1.25,  -1.0,
:               -0.75,  -0.5, -0.25,  0.25,   0.5,  0.75,   1.0,  1.25,   1.5,
:                1.75,   2.0,  2.25,   2.5,  2.75,   3.0,  3.25,   3.5,  3.75,
:                 4.0,  4.25,   4.5,  4.75,   5.0,  5.25,   5.5,  5.75,   6.0],
:              dtype='float64', name='ev')
: <matplotlib.collections.PathCollection at 0x7fc6d02dc7f0>
[[file:./.ob-jupyter/56560a96df6e20f70b64f853bca526dfd39f0b0c.png]]
:END:

#+BEGIN_SRC jupyter-python
mean_mse = err_df.loc["mse"].aggregate("mean", axis=0).to_numpy()
mse_prob = 1 - (mean_mse / mean_mse.max())
plt.scatter(x=errors.columns, y=F.softmax(torch.tensor(mse_prob),dim=0))
#+END_SRC

#+RESULTS:
:RESULTS:
: <matplotlib.collections.PathCollection at 0x7fc6cea16b20>
[[file:./.ob-jupyter/be8b74901ac258ffb3e6fb5add2e59e76397f938.png]]
:END:

* Testing Reconstruction model trained with above probabilities

First things first, load the model:
#+BEGIN_SRC jupyter-python
from IPython.utils import io
from pytorch_lightning import Trainer

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
gpus = "0" if torch.cuda.is_available() else None


def get_best_model(model_cls, backbone: str):

    with io.capture_output(stdout=True, stderr=True) as _captured:
        trainer = Trainer(gpus=gpus, progress_bar_refresh_rate=0)
        test_scores = dict()
        for ckpt in (ROOT_DIR / "checkpoints").glob(f"*{backbone}*.ckpt"):
            model = model_cls.load_from_checkpoint(checkpoint_path=str(ckpt))
            model.eval()

            test_score = trainer.test(model)["test_loss"]
            test_scores[str(ckpt.stem)] = test_score, model, ckpt.stem

    best_model = min(test_scores.values(), key=lambda x: x[0])
    return best_model
#+END_SRC

#+RESULTS:

This has been run once so no need to do it again, we have the saved name for the model now
#+BEGIN_SRC jupyter-python
from dhdrnet.reconstruction_model import RCNet
from dhdrnet.histogram_model import HistogramNet
from dhdrnet.model import DHDRMobileNet_v3, DHDRSqueezeNet
from dhdrnet.resnet_model import DHDRResnet
from dhdrnet.Dataset import LUTDataset, RCDataset
from pytorch_lightning import seed_everything


seed_everything(19)

# trainer = Trainer(gpus=gpus)
# name = "dhdr_reconstruction_final2020-09-15T17:39:29.915663"
# rcnet_model = RCNet.load_from_checkpoint(
#     checkpoint_path=str(ROOT_DIR / "checkpoints" / f"{name}.ckpt")
# ).to(device)

rcnet_score, rcnet_model, rc_name = get_best_model(RCNet, "reconstruction")
mobile_score, mobile_model, mobile_name = get_best_model(DHDRMobileNet_v3, "mobile_v3")
resnet_score, resnet_model, resnet_name = get_best_model(DHDRResnet, "resnet")
squeeze_score, squeeze_model, squeeze_name = get_best_model(DHDRSqueezeNet, "squeeze")
print(f"{mobile_score=}")
print(f"{resnet_score=}")
print(f"{squeeze_score=}")
#+END_SRC

#+RESULTS:
:RESULTS:
: GPU available: True, used: True
: TPU available: False, using: 0 TPU cores
: CUDA_VISIBLE_DEVICES: [0]
# [goto error]
#+begin_example
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-15-0b2caf67b469> in <module>
     15 # ).to(device)
     16 
---> 17 rcnet_score, rcnet_model, rc_name = get_best_model(RCNet, "reconstruction")
     18 mobile_score, mobile_model, mobile_name = get_best_model(DHDRMobileNet_v3, "mobile_v3")
     19 resnet_score, resnet_model, resnet_name = get_best_model(DHDRResnet, "resnet")

<ipython-input-9-d5b54893637f> in get_best_model(model_cls, backbone)
     12         test_scores = dict()
     13         for ckpt in (ROOT_DIR / "checkpoints").glob(f"*{backbone}*"):
---> 14             model = model_cls.load_from_checkpoint(checkpoint_path=str(ckpt))
     15             model.eval()
     16 

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/pytorch_lightning/core/saving.py in load_from_checkpoint(cls, checkpoint_path, map_location, hparams_file, tags_csv, *args, **kwargs)
    140             checkpoint = pl_load(checkpoint_path, map_location=map_location)
    141         else:
--> 142             checkpoint = pl_load(checkpoint_path, map_location=lambda storage, loc: storage)
    143 
    144         # add the hparams from csv file to checkpoint

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py in load(path_or_url, map_location)
      7 def load(path_or_url: str, map_location=None):
      8     if urlparse(path_or_url).scheme == '' or Path(path_or_url).drive:  # no scheme or with a drive letter
----> 9         return torch.load(path_or_url, map_location=map_location)
     10     else:
     11         return torch.hub.load_state_dict_from_url(path_or_url, map_location=map_location)

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)
    591                     return torch.jit.load(f)
    592                 return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
--> 593         return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
    594 
    595 

~/.cache/pypoetry/virtualenvs/dhdrnet-md5k9ngR-py3.8/lib/python3.8/site-packages/torch/serialization.py in _legacy_load(f, map_location, pickle_module, **pickle_load_args)
    778     for key in deserialized_storage_keys:
    779         assert key in deserialized_objects
--> 780         deserialized_objects[key]._set_from_file(f, offset, f_should_read_directly)
    781         if offset is not None:
    782             offset = f.tell()

RuntimeError: unexpected EOF, expected 8 more bytes. The file might be corrupted.
#+end_example
:END:
Let's get some predictions out of the model and evaluate it.

#+BEGIN_SRC jupyter-python
from torch.utils.data import DataLoader
from more_itertools import flatten, one, collapse

evs = torch.tensor(test_data.evs)


def get_ev(evs, indices):
    return [evs[i] for i in indices]


def get_rec_predictions(model, batch, k=4):
    X, y_true, names = batch
    y_pred = model(X.to(device))
    _, pred_ev_idx = torch.topk(y_pred, k, dim=1)
    pred_ev = evs[pred_ev_idx]

    true_ev_idx = torch.argmax(y_true, dim=1)
    true_ev = evs[true_ev_idx]
    return zip(names, pred_ev.numpy(), true_ev.numpy())


def get_ce_predictions(model, batch, k=4):
    X, y_true_idx, names = batch
    y_pred = model(X.to(device))
    _, pred_ev_idx = torch.topk(y_pred, k, dim=1)
    pred_ev = evs[pred_ev_idx]

    true_ev = evs[y_true_idx]
    return zip(names, pred_ev.numpy(), true_ev.numpy())
#+END_SRC

#+RESULTS:


The idea here is to get the percentage of top-k that contains the right answer,
and the mean distance between the answers and the true ev
#+BEGIN_SRC jupyter-python
def topk_accuracy(model, evaluator, dataloader, k=4):
    model.eval()
    names, pred_evs, true_evs = zip(
        *flatten((evaluator(model, batch, k) for batch in dataloader))
    )

    c = 0
    for predicted_evs, true_ev in zip(pred_evs, true_evs):
        if true_ev in predicted_evs:
            c += 1

    return f"{100*c / len(names):.2f}%"
#+END_SRC

#+RESULTS:

#+BEGIN_SRC jupyter-python
rc_data = test_data
reconstruction_loader = DataLoader(rc_data, batch_size=70, num_workers=8)

lut_data = LUTDataset(
    df=pd.read_csv(ROOT_DIR / "precomputed_data" / "store_current.csv"),
    exposure_path=DATA_DIR / "correct_exposures" / "exposures",
    raw_dir=DATA_DIR / "dngs",
    name_list=ROOT_DIR / "precomputed_data" / "test_current.csv",
    transform=Compose([Resize((300, 300)), ToTensor()]),
)
lut_loader = DataLoader(lut_data, batch_size=70, num_workers=8)

#+END_SRC

#+RESULTS:


#+BEGIN_SRC jupyter-python
rc_acc = topk_accuracy(rcnet_model, get_rec_predictions, reconstruction_loader, k=3)
resnet_acc = topk_accuracy(resnet_model, get_ce_predictions, lut_loader, k=3)
mobile_acc = topk_accuracy(mobile_model, get_ce_predictions, lut_loader, k=3)
squeeze_acc = topk_accuracy(squeeze_model, get_ce_predictions, lut_loader, k=3)

print(f"{rc_acc=}")
print(f"{resnet_acc=}")
print(f"{mobile_acc=}")
print(f"{squeeze_acc=}")
#+END_SRC

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: <ipython-input-19-a2453bad8f1e> in <module>
: ----> 1 rc_acc = topk_accuracy(rcnet_model, get_rec_predictions, reconstruction_loader, k=3)
:       2 resnet_acc = topk_accuracy(resnet_model, get_ce_predictions, lut_loader, k=3)
:       3 mobile_acc = topk_accuracy(mobile_model, get_ce_predictions, lut_loader, k=3)
:       4 squeeze_acc = topk_accuracy(squeeze_model, get_ce_predictions, lut_loader, k=3)
:       5 
: 
: NameError: name 'rcnet_model' is not defined
:END:
